import os
import json
import logging
import time
import random
from kafka import KafkaConsumer
from influxdb_client import InfluxDBClient, Point
from concurrent.futures import ThreadPoolExecutor
from threading import Lock
from datetime import datetime

# C·∫•u h√¨nh logging v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# C·∫•u h√¨nh Kafka
BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:39092").split(",")
TOPICS = ["sensor_data_farm1", "sensor_data_farm2"]
GROUP_ID = os.getenv("KAFKA_CONSUMER_GROUP", "sensor_group")

# C·∫•u h√¨nh InfluxDB
INFLUXDB_URL = os.getenv("INFLUXDB_URL", "http://localhost:8086")
INFLUXDB_TOKEN = os.getenv("INFLUXDB_TOKEN", "hvCR3-q3CQmPEG2WHrO_q09kqdEky_kLd7hf28142lxANDGS9KnnZZPAb_Hz0iLYVWBeyj-Vf5CQZZlOgn63EQ==")
INFLUXDB_ORG = os.getenv("INFLUXDB_ORG", "Ho Chi Minh University of Technology")
INFLUXDB_BUCKET = os.getenv("INFLUXDB_BUCKET", "sensor_data")

# C√°c tham s·ªë c·∫•u h√¨nh th√™m
CHANGE_THRESHOLD = float(os.getenv("CHANGE_THRESHOLD", 0.5))
MAX_WORKERS = int(os.getenv("MAX_WORKERS", 4))
MAX_RETRIES = 3

def create_influx_client():
    """
    T·∫°o v√† tr·∫£ v·ªÅ InfluxDB client c√πng v·ªõi write API.
    """
    try:
        client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)
        write_api = client.write_api()
        return client, write_api
    except Exception as e:
        logger.error(f" Kh√¥ng th·ªÉ k·∫øt n·ªëi InfluxDB: {e}")
        exit(1)

def create_kafka_consumer():
    """
    T·∫°o v√† tr·∫£ v·ªÅ Kafka Consumer.
    """
    try:
        consumer = KafkaConsumer(
            *TOPICS,
            bootstrap_servers=BOOTSTRAP_SERVERS,
            security_protocol='PLAINTEXT',
            value_deserializer=lambda x: json.loads(x.decode('utf-8')),
            auto_offset_reset='earliest',
            group_id=GROUP_ID
        )
        return consumer
    except Exception as e:
        logger.error(f" Kh√¥ng th·ªÉ kh·ªüi t·∫°o Kafka Consumer: {e}")
        exit(1)

# Kh·ªüi t·∫°o thread pool v√† lock ƒë·ªÉ ƒë·∫£m b·∫£o thread-safe cho bi·∫øn last_values
pool = ThreadPoolExecutor(max_workers=MAX_WORKERS)
last_values = {}
lock = Lock()

def validate_timestamp(ts):
    """
    Ki·ªÉm tra v√† chuy·ªÉn ƒë·ªïi timestamp. N·∫øu kh√¥ng h·ª£p l·ªá, tr·∫£ v·ªÅ th·ªùi gian hi·ªán t·∫°i.
    """
    if ts is None:
        return datetime.utcnow().isoformat()
    try:
        # N·∫øu timestamp ·ªü ƒë·ªãnh d·∫°ng ISO 8601, tr·∫£ v·ªÅ nh∆∞ v·∫≠y
        datetime.fromisoformat(ts)
        return ts
    except Exception:
        logger.warning(f"Timestamp kh√¥ng h·ª£p l·ªá ({ts}), s·ª≠ d·ª•ng th·ªùi gian hi·ªán t·∫°i.")
        return datetime.utcnow().isoformat()

def process_message(data, write_api):
    """
    X·ª≠ l√Ω m·ªôt message t·ª´ Kafka v√† ghi d·ªØ li·ªáu v√†o InfluxDB n·∫øu c√≥ thay ƒë·ªïi ƒë√°ng k·ªÉ.

    Args:
        data (dict): D·ªØ li·ªáu c·∫£m bi·∫øn t·ª´ Kafka.
        write_api: InfluxDB Write API.
    """
    sensor_id = data.get("sensor_id")
    if sensor_id is None:
        logger.warning(" D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá, thi·∫øu sensor_id.")
        return

    try:
        current_temp = float(data.get("temperature"))
    except (TypeError, ValueError):
        logger.warning(f"Gi√° tr·ªã temperature kh√¥ng h·ª£p l·ªá: {data.get('temperature')}")
        return

    with lock:
        if sensor_id in last_values and abs(last_values[sensor_id] - current_temp) < CHANGE_THRESHOLD:
            logger.debug(f" B·ªè qua d·ªØ li·ªáu kh√¥ng thay ƒë·ªïi ƒë√°ng k·ªÉ: {data}")
            return
        last_values[sensor_id] = current_temp

    timestamp = validate_timestamp(data.get("timestamp"))

    point = Point("sensor_data") \
        .tag("sensor_id", sensor_id) \
        .field("temperature", current_temp) \
        .field("humidity", data.get("humidity")) \
        .time(timestamp)

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=point)
            logger.info(f" D·ªØ li·ªáu ƒë√£ l∆∞u v√†o InfluxDB: {data}")
            break
        except Exception as e:
            logger.warning(f" L·ªói khi ghi v√†o InfluxDB (l·∫ßn {attempt}/{MAX_RETRIES}): {e}")
            if attempt < MAX_RETRIES:
                sleep_time = (2 ** attempt) + random.uniform(0, 0.1)
                time.sleep(sleep_time)
            else:
                logger.error(" Ghi d·ªØ li·ªáu th·∫•t b·∫°i sau nhi·ªÅu l·∫ßn retry.")

def consume_messages(consumer, write_api, influx_client):
    """
    L·∫Øng nghe message t·ª´ Kafka v√† x·ª≠ l√Ω ch√∫ng song song.

    Args:
        consumer: Kafka Consumer instance.
        write_api: InfluxDB Write API.
        influx_client: InfluxDB Client instance.
    """
    logger.info(f"üì° Consumer ƒëang l·∫Øng nghe tr√™n c√°c topics: {TOPICS}...")
    try:
        for message in consumer:
            data = message.value
            pool.submit(process_message, data, write_api)
    except KeyboardInterrupt:
        logger.warning(" Consumer d·ª´ng do ng∆∞·ªùi d√πng y√™u c·∫ßu.")
    finally:
        consumer.close()
        influx_client.close()
        pool.shutdown(wait=True)
        logger.info(" Consumer ƒë√£ ƒë√≥ng k·∫øt n·ªëi.")

def main():
    """
    H√†m ch√≠nh kh·ªüi t·∫°o c√°c client v√† b·∫Øt ƒë·∫ßu qu√° tr√¨nh consume message.
    """
    influx_client, write_api = create_influx_client()
    consumer = create_kafka_consumer()
    consume_messages(consumer, write_api, influx_client)

if __name__ == "__main__":
    main()
